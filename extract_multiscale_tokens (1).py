"""
Multi-scale Visual Token Extractor for Infinity Model

è¿™ä¸ªè„šæœ¬çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯ä»è¾“å…¥å›¾ç‰‡ä¸­æå–å‰4ä¸ªscaleçš„ä¸¤ç§è§†è§‰è¡¨å¾ï¼š
1. åŸå§‹tokenï¼ˆgt_tokensï¼‰ï¼šæœªç»æ‰°åŠ¨çš„çœŸå®è§†è§‰è¡¨å¾
2. çº æ­£åtokenï¼ˆcorrected_tokensï¼‰ï¼šç»è¿‡bitwise self-correctionå¤„ç†çš„è¡¨å¾

ä½¿ç”¨æ–¹æ³•ï¼š
1. ä¿®æ”¹IMAGE_PATHå˜é‡ä¸ºæ‚¨è¦åˆ†æçš„å›¾ç‰‡è·¯å¾„
2. è¿è¡Œ: python extract_multiscale_tokens.py
3. æŸ¥çœ‹è¾“å‡ºç›®å½•ä¸­ä¿å­˜çš„tokenæ–‡ä»¶å’Œå¯è§†åŒ–ç»“æœ
"""

import os
import random
import torch
torch.cuda.set_device(0)
import cv2
import numpy as np
from tools.run_infinity import *
from PIL import Image
import torch.nn.functional as F
from datetime import datetime

# ===================== é…ç½®éƒ¨åˆ† =====================
# åªéœ€è¦ä¿®æ”¹è¿™ä¸ªè·¯å¾„ï¼
IMAGE_PATH = "path/to/your/image.jpg"  # ä¿®æ”¹ä¸ºæ‚¨çš„å›¾ç‰‡è·¯å¾„

# æ¨¡å‹é…ç½®ï¼ˆä¸inf.pyä¿æŒä¸€è‡´ï¼‰
model_path = 'weights/infinity_8b_512x512_weights'
vae_path = 'weights/infinity_vae_d56_f8_14_patchify.pth'
text_encoder_ckpt = 'weights/flan-t5-xl-official'

# è¾“å‡ºç›®å½•
OUTPUT_DIR = "extracted_tokens"

# ===================== æ¨¡å‹é…ç½® =====================
args = argparse.Namespace(
    pn='0.25M',
    model_path=model_path,
    cfg_insertion_layer=0,
    vae_type=14,
    vae_path=vae_path,
    add_lvl_embeding_only_first_block=1,
    use_bit_label=1,
    model_type='infinity_8b',
    rope2d_each_sa_layer=1,
    rope2d_normalized_by_hw=2,
    use_scale_schedule_embedding=0,
    sampling_per_bits=1,
    text_encoder_ckpt=text_encoder_ckpt,
    text_channels=2048,
    apply_spatial_patchify=1,
    h_div_w_template=1.000,
    use_flex_attn=0,
    cache_dir='/dev/shm',
    checkpoint_type='torch_shard',
    seed=0,
    bf16=1,
)

class MultiscaleTokenExtractor:
    """
    å¤šå°ºåº¦tokenæå–å™¨
    
    è¿™ä¸ªç±»å°è£…äº†ä»å›¾ç‰‡åˆ°å¤šå°ºåº¦è§†è§‰è¡¨å¾çš„å®Œæ•´æµç¨‹ï¼Œ
    åŒ…æ‹¬é¢„å¤„ç†ã€VAEç¼–ç ã€Bitwise Self-Correctionç­‰æ­¥éª¤ã€‚
    """
    
    def __init__(self, args):
        self.args = args
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.vae = None
        self.scale_schedule = None
        self.vae_scale_schedule = None
        
        # BSCç›¸å…³å‚æ•°
        self.noise_apply_layers = 4  # å‰4å±‚éƒ½å¯èƒ½æ·»åŠ å™ªå£°
        self.noise_apply_strength = 0.15  # å™ªå£°å¼ºåº¦
        
    def load_model(self):
        """åŠ è½½VAEæ¨¡å‹"""
        print("æ­£åœ¨åŠ è½½VAEæ¨¡å‹...")
        self.vae = load_visual_tokenizer(self.args)
        print(f"VAEåŠ è½½å®Œæˆã€‚Codebookç»´åº¦: {self.vae.codebook_dim}")
        
        # è·å–scale_schedule
        h_div_w_template = self.args.h_div_w_template
        self.scale_schedule = dynamic_resolution_h_w[h_div_w_template][self.args.pn]['scales']
        self.scale_schedule = [(1, h, w) for (_, h, w) in self.scale_schedule]
        
        # å¦‚æœä½¿ç”¨spatial_patchifyï¼Œè½¬æ¢ä¸ºvae_scale_schedule
        if self.args.apply_spatial_patchify:
            self.vae_scale_schedule = [(pt, 2*ph, 2*pw) for pt, ph, pw in self.scale_schedule]
        else:
            self.vae_scale_schedule = self.scale_schedule
            
        print(f"Scale schedule: {self.scale_schedule[:6]}")
        print(f"VAE scale schedule: {self.vae_scale_schedule[:6]}")
        
    def preprocess_image(self, image_path):
        """
        å›¾ç‰‡é¢„å¤„ç†ï¼šå°†ä»»æ„å°ºå¯¸çš„å›¾ç‰‡è½¬æ¢ä¸º512x512
        
        å¤„ç†æµç¨‹ï¼š
        1. åŠ è½½å›¾ç‰‡
        2. æ™ºèƒ½resizeï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
        3. Center cropåˆ°512x512
        4. å½’ä¸€åŒ–åˆ°[-1, 1]èŒƒå›´
        """
        print(f"æ­£åœ¨é¢„å¤„ç†å›¾ç‰‡: {image_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        
        # åŠ è½½å›¾ç‰‡
        pil_image = Image.open(image_path).convert('RGB')
        original_size = pil_image.size
        print(f"åŸå§‹å›¾ç‰‡å°ºå¯¸: {original_size[0]}x{original_size[1]}")
        
        # ä½¿ç”¨transformå‡½æ•°è¿›è¡Œé¢„å¤„ç†
        tgt_h, tgt_w = 512, 512
        transformed = transform(pil_image, tgt_h, tgt_w)
        
        # æ·»åŠ batchç»´åº¦å¹¶ç§»åˆ°GPU
        inp_B3HW = transformed.unsqueeze(0).to(self.device)
        print(f"é¢„å¤„ç†åå½¢çŠ¶: {inp_B3HW.shape}")
        print(f"æ•°å€¼èŒƒå›´: [{inp_B3HW.min():.3f}, {inp_B3HW.max():.3f}]")
        
        return inp_B3HW, pil_image
        
    def extract_raw_features(self, inp_B3HW):
        """
        ä½¿ç”¨VAEæå–åŸå§‹ç‰¹å¾
        
        è¿™ä¸€æ­¥å°†å›¾ç‰‡ç¼–ç ä¸ºè¿ç»­çš„ç‰¹å¾è¡¨ç¤ºï¼Œ
        ä½œä¸ºåç»­å¤šå°ºåº¦é‡åŒ–çš„è¾“å…¥ã€‚
        """
        print("\næ­£åœ¨æå–VAEåŸå§‹ç‰¹å¾...")
        
        with torch.no_grad():
            raw_features, _, _ = self.vae.encode_for_raw_features(
                inp_B3HW, scale_schedule=self.vae_scale_schedule
            )
        
        print(f"Raw featureså½¢çŠ¶: {raw_features.shape}")
        print(f"Raw featuresæ•°å€¼èŒƒå›´: [{raw_features.min():.3f}, {raw_features.max():.3f}]")
        
        return raw_features
        
    def extract_multiscale_tokens(self, raw_features):
        """
        æå–å¤šå°ºåº¦tokenè¡¨å¾
        
        è¿™æ˜¯æ•´ä¸ªæµç¨‹çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œå®ç°äº†Bitwise Self-Correctionæœºåˆ¶ï¼š
        1. é€å°ºåº¦å¤„ç†residualç‰¹å¾
        2. å¯¹æ¯ä¸ªå°ºåº¦è¿›è¡ŒBSQé‡åŒ–
        3. åœ¨å‰å‡ ä¸ªå°ºåº¦æ·»åŠ å™ªå£°æ¨¡æ‹Ÿæ¨ç†é”™è¯¯
        4. ç´¯ç§¯å„å°ºåº¦çš„è´¡çŒ®
        
        è¿”å›ä¸¤ç§tokenï¼š
        - gt_tokens: çœŸå®çš„ã€æœªæ‰°åŠ¨çš„token
        - corrected_tokens: ç»è¿‡self-correctionçš„token
        """
        print("\næ­£åœ¨æå–å¤šå°ºåº¦token...")
        
        B = raw_features.shape[0]
        
        # å¤„ç†ç»´åº¦ï¼šç¡®ä¿æ˜¯5D tensor (B, C, T, H, W)
        if raw_features.dim() == 4:
            codes_out = raw_features.unsqueeze(2)  # æ·»åŠ æ—¶é—´ç»´åº¦
        else:
            codes_out = raw_features
            
        print(f"åˆå§‹codes_outå½¢çŠ¶: {codes_out.shape}")
        
        # åˆå§‹åŒ–ç´¯ç§¯å˜é‡å’Œç»“æœåˆ—è¡¨
        cum_var_input = 0
        gt_tokens = []  # çœŸå®token
        corrected_tokens = []  # çº æ­£åtoken
        
        with torch.no_grad():
            # é€å°ºåº¦å¤„ç†ï¼ˆåªå¤„ç†å‰4ä¸ªå°ºåº¦ï¼‰
            for si, (pt, ph, pw) in enumerate(self.vae_scale_schedule[:4]):
                print(f"\n--- å¤„ç†Scale {si}: ({pt}, {ph}, {pw}) ---")
                
                # è®¡ç®—å½“å‰å°ºåº¦çš„residual
                residual = codes_out - cum_var_input
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªå°ºåº¦ï¼Œéœ€è¦æ’å€¼åˆ°å½“å‰å°ºåº¦çš„åˆ†è¾¨ç‡
                if si < len(self.vae_scale_schedule) - 1:
                    residual = F.interpolate(
                        residual, 
                        size=(pt, ph, pw), 
                        mode=self.vae.quantizer.z_interplote_down
                    ).contiguous()
                
                print(f"Residualå½¢çŠ¶: {residual.shape}")
                
                # BSQé‡åŒ–å¾—åˆ°çœŸå®token
                quantized, _, bit_indices, _ = self.vae.quantizer.lfq(residual)
                gt_tokens.append(bit_indices.clone())
                
                print(f"Scale {si} tokenå½¢çŠ¶: {bit_indices.shape}")
                print(f"Tokenæ•°é‡: {bit_indices.numel() // bit_indices.shape[-1]} tokensï¼Œæ¯ä¸ªtoken {bit_indices.shape[-1]} bits")
                
                # ç”Ÿæˆçº æ­£åçš„tokenï¼ˆæ¨¡æ‹Ÿbitwise self-correctionï¼‰
                corrected_bit_indices = bit_indices.clone()
                
                # åœ¨å‰å‡ ä¸ªå°ºåº¦æ·»åŠ å™ªå£°
                if si < self.noise_apply_layers:
                    # éšæœºé€‰æ‹©è¦ç¿»è½¬çš„bits
                    noise_strength = self.noise_apply_strength * (1.0 - si * 0.05)  # å°ºåº¦è¶Šé«˜å™ªå£°è¶Šå°‘
                    mask = torch.rand_like(bit_indices, dtype=torch.float) < noise_strength
                    corrected_bit_indices[mask] = 1 - corrected_bit_indices[mask]
                    
                    flipped_bits = mask.sum().item()
                    total_bits = bit_indices.numel()
                    print(f"æ·»åŠ å™ªå£°ï¼šç¿»è½¬äº† {flipped_bits}/{total_bits} bits ({flipped_bits/total_bits*100:.2f}%)")
                else:
                    print("æœªæ·»åŠ å™ªå£°ï¼ˆå°ºåº¦è¿‡é«˜ï¼‰")
                
                corrected_tokens.append(corrected_bit_indices)
                
                # ç´¯ç§¯å½“å‰å°ºåº¦çš„è´¡çŒ®
                cum_var_input = cum_var_input + F.interpolate(
                    quantized, 
                    size=self.vae_scale_schedule[-1][::-1],  # (W, H, T) -> (T, H, W)
                    mode=self.vae.quantizer.z_interplote_up
                ).contiguous()
        
        print(f"\næå–å®Œæˆï¼å…±æå–äº† {len(gt_tokens)} ä¸ªå°ºåº¦çš„token")
        return gt_tokens, corrected_tokens
    
    def reconstruct_images(self, tokens_list, token_type=""):
        """
        ä»tokené‡æ„å›¾ç‰‡
        
        ä½¿ç”¨VAEçš„decoderå°†æ¯ä¸ªå°ºåº¦çš„tokené‡æ„ä¸ºå›¾ç‰‡ï¼Œ
        è¿™æœ‰åŠ©äºå¯è§†åŒ–ä¸åŒå°ºåº¦æ•è·çš„è§†è§‰ä¿¡æ¯ã€‚
        """
        print(f"\næ­£åœ¨é‡æ„{token_type}å›¾ç‰‡...")
        
        reconstructed_images = []
        
        with torch.no_grad():
            for si, tokens in enumerate(tokens_list):
                try:
                    # å°†bit indicesè½¬æ¢ä¸ºcodes
                    codes = self.vae.quantizer.lfq.indices_to_codes(
                        tokens, label_type='bit_label'
                    )
                    
                    # æ’å€¼åˆ°æœ€ç»ˆå°ºå¯¸å¹¶è§£ç 
                    final_size = self.vae_scale_schedule[-1]
                    codes_upsampled = F.interpolate(
                        codes, 
                        size=final_size, 
                        mode=self.vae.quantizer.z_interplote_up
                    )
                    
                    # VAEè§£ç 
                    if codes_upsampled.dim() == 5:
                        codes_upsampled = codes_upsampled.squeeze(2)  # ç§»é™¤æ—¶é—´ç»´åº¦
                    
                    reconstructed = self.vae.decode(codes_upsampled)
                    
                    # è½¬æ¢ä¸ºå¯æ˜¾ç¤ºçš„å›¾ç‰‡æ ¼å¼
                    img = (reconstructed + 1) / 2  # [-1,1] -> [0,1]
                    img = img.clamp(0, 1)
                    img = img.squeeze(0).permute(1, 2, 0)  # CHW -> HWC
                    img = (img * 255).cpu().numpy().astype(np.uint8)
                    
                    reconstructed_images.append(img)
                    print(f"Scale {si} é‡æ„å›¾ç‰‡å½¢çŠ¶: {img.shape}")
                    
                except Exception as e:
                    print(f"Scale {si} é‡æ„å¤±è´¥: {e}")
                    # åˆ›å»ºç©ºç™½å›¾ç‰‡ä½œä¸ºå ä½ç¬¦
                    reconstructed_images.append(np.zeros((512, 512, 3), dtype=np.uint8))
        
        return reconstructed_images
    
    def save_tokens(self, gt_tokens, corrected_tokens, output_dir, image_name):
        """ä¿å­˜æå–çš„tokenåˆ°æ–‡ä»¶"""
        print(f"\næ­£åœ¨ä¿å­˜tokenåˆ° {output_dir}")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜tokenæ•°æ®
        token_data = {
            'gt_tokens': gt_tokens,
            'corrected_tokens': corrected_tokens,
            'scale_schedule': self.scale_schedule[:4],
            'vae_scale_schedule': self.vae_scale_schedule[:4],
            'image_name': image_name,
            'extraction_time': datetime.now().isoformat(),
            'model_config': {
                'vae_type': self.args.vae_type,
                'apply_spatial_patchify': self.args.apply_spatial_patchify,
                'codebook_dim': self.vae.codebook_dim,
            }
        }
        
        token_file = os.path.join(output_dir, f"{image_name}_tokens.pt")
        torch.save(token_data, token_file)
        print(f"Tokenæ•°æ®å·²ä¿å­˜åˆ°: {token_file}")
        
        # ä¿å­˜tokenç»Ÿè®¡ä¿¡æ¯
        stats_file = os.path.join(output_dir, f"{image_name}_stats.txt")
        with open(stats_file, 'w') as f:
            f.write(f"Multi-scale Token Extraction Statistics\n")
            f.write(f"========================================\n\n")
            f.write(f"Image: {image_name}\n")
            f.write(f"Extraction Time: {datetime.now()}\n")
            f.write(f"Model: Infinity-8B (512x512)\n")
            f.write(f"VAE Type: {self.args.vae_type}\n")
            f.write(f"Codebook Dimension: {self.vae.codebook_dim}\n")
            f.write(f"Spatial Patchify: {self.args.apply_spatial_patchify}\n\n")
            
            f.write("Scale Information:\n")
            for i, (gt_token, corrected_token) in enumerate(zip(gt_tokens, corrected_tokens)):
                scale_info = self.vae_scale_schedule[i]
                token_count = gt_token.shape[1] * gt_token.shape[2] * gt_token.shape[3]
                bit_count = token_count * gt_token.shape[-1]
                
                f.write(f"Scale {i}: {scale_info}\n")
                f.write(f"  Tokenå½¢çŠ¶: {gt_token.shape}\n")
                f.write(f"  Tokenæ•°é‡: {token_count}\n")
                f.write(f"  æ€»bitæ•°: {bit_count}\n")
                f.write(f"  æ¯token bitæ•°: {gt_token.shape[-1]}\n\n")
        
        print(f"ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_file}")
        
    def add_token_info_to_image(self, img, scale_idx, token_count, token_type):
        """åœ¨å›¾ç‰‡ä¸Šæ·»åŠ tokenä¿¡æ¯æ ‡æ³¨"""
        img_with_text = img.copy()
        
        # å‡†å¤‡æ–‡æœ¬ä¿¡æ¯
        text_lines = [
            f"Scale {scale_idx}",
            f"{token_count} tokens",
            f"({token_type})"
        ]
        
        # è®¾ç½®æ–‡æœ¬å‚æ•°
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.8
        color = (255, 255, 255)  # ç™½è‰²æ–‡å­—
        thickness = 2
        bg_color = (0, 0, 0)  # é»‘è‰²èƒŒæ™¯
        
        # è®¡ç®—æ–‡æœ¬å¤§å°ç”¨äºèƒŒæ™¯
        text_sizes = []
        for text in text_lines:
            (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
            text_sizes.append((text_width, text_height + baseline))
        
        max_width = max([size[0] for size in text_sizes])
        total_height = sum([size[1] for size in text_sizes]) + 10  # é¢å¤–é—´è·
        
        # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
        overlay = img_with_text.copy()
        cv2.rectangle(overlay, (10, 10), (10 + max_width + 20, 10 + total_height), bg_color, -1)
        cv2.addWeighted(overlay, 0.7, img_with_text, 0.3, 0, img_with_text)
        
        # ç»˜åˆ¶æ–‡æœ¬
        y_offset = 35
        for i, text in enumerate(text_lines):
            cv2.putText(img_with_text, text, (20, y_offset), font, font_scale, color, thickness)
            y_offset += text_sizes[i][1] + 5
        
        return img_with_text

    def save_visualizations(self, gt_reconstructed, corrected_reconstructed, 
                          original_image, output_dir, image_name, gt_tokens, corrected_tokens):
        """ä¿å­˜å¯è§†åŒ–ç»“æœ"""
        print(f"\næ­£åœ¨ä¿å­˜å¯è§†åŒ–ç»“æœ...")
        
        # ä¿å­˜åŸå§‹å›¾ç‰‡
        original_path = os.path.join(output_dir, f"{image_name}_original.jpg")
        original_image.save(original_path)
        
        # ä¿å­˜å„ä¸ªå°ºåº¦çš„é‡æ„å›¾ç‰‡ï¼ˆå¸¦tokenä¿¡æ¯æ ‡æ³¨ï¼‰
        for i, (gt_img, corrected_img) in enumerate(zip(gt_reconstructed, corrected_reconstructed)):
            # è®¡ç®—å½“å‰å°ºåº¦çš„tokenæ•°é‡
            token_shape = gt_tokens[i].shape  # (B, T, H, W, D)
            token_count = token_shape[1] * token_shape[2] * token_shape[3]  # T * H * W
            
            # ä¸ºå›¾ç‰‡æ·»åŠ tokenä¿¡æ¯æ ‡æ³¨
            gt_img_annotated = self.add_token_info_to_image(gt_img, i, token_count, "Original")
            corrected_img_annotated = self.add_token_info_to_image(corrected_img, i, token_count, "Corrected")
            
            # ä¿å­˜æ ‡æ³¨åçš„å›¾ç‰‡
            gt_path = os.path.join(output_dir, f"{image_name}_scale{i}_gt_reconstructed.jpg")
            cv2.imwrite(gt_path, gt_img_annotated[:, :, ::-1])  # RGB -> BGR
            
            corrected_path = os.path.join(output_dir, f"{image_name}_scale{i}_corrected_reconstructed.jpg")
            cv2.imwrite(corrected_path, corrected_img_annotated[:, :, ::-1])  # RGB -> BGR
            
            print(f"Scale {i} å¯è§†åŒ–å·²ä¿å­˜ ({token_count} tokens)")
        
        # åˆ›å»ºå¯¹æ¯”å›¾
        self.create_comparison_visualization(
            gt_reconstructed, corrected_reconstructed, 
            output_dir, image_name, gt_tokens
        )
    
    def create_comparison_visualization(self, gt_reconstructed, corrected_reconstructed, 
                                     output_dir, image_name, gt_tokens):
        """åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–å›¾"""
        print("æ­£åœ¨åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–...")
        
        # åˆ›å»º2x4çš„å¯¹æ¯”å›¾ (2è¡Œï¼Œ4åˆ—)
        fig_height = 512 * 2
        fig_width = 512 * 4
        comparison = np.zeros((fig_height, fig_width, 3), dtype=np.uint8)
        
        for i in range(4):
            # è®¡ç®—tokenæ•°é‡
            token_shape = gt_tokens[i].shape
            token_count = token_shape[1] * token_shape[2] * token_shape[3]
            
            # ä¸ºé‡æ„å›¾ç‰‡æ·»åŠ æ ‡æ³¨
            gt_img_annotated = self.add_token_info_to_image(gt_reconstructed[i], i, token_count, "Original")
            corrected_img_annotated = self.add_token_info_to_image(corrected_reconstructed[i], i, token_count, "Corrected")
            
            # ç¬¬ä¸€è¡Œï¼šçœŸå®tokené‡æ„
            y1, y2 = 0, 512
            x1, x2 = i * 512, (i + 1) * 512
            comparison[y1:y2, x1:x2] = gt_img_annotated
            
            # ç¬¬äºŒè¡Œï¼šçº æ­£åtokené‡æ„
            y1, y2 = 512, 1024
            comparison[y1:y2, x1:x2] = corrected_img_annotated
        
        # ä¿å­˜å¯¹æ¯”å›¾
        comparison_path = os.path.join(output_dir, f"{image_name}_comparison.jpg")
        cv2.imwrite(comparison_path, comparison[:, :, ::-1])  # RGB -> BGR
        print(f"å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {comparison_path}")
        
    def save_tokens_as_txt(self, gt_tokens, corrected_tokens, output_dir, image_name):
        """å°†tokenä»¥äººç±»å¯è¯»çš„æ ¼å¼ä¿å­˜åˆ°txtæ–‡ä»¶"""
        print(f"\næ­£åœ¨ä¿å­˜tokenæ•°æ®åˆ°txtæ–‡ä»¶...")
        
        # ä¿å­˜çœŸå®token
        gt_txt_path = os.path.join(output_dir, f"{image_name}_gt_tokens.txt")
        with open(gt_txt_path, 'w') as f:
            f.write("=" * 80 + "\n")
            f.write("Infinityæ¨¡å‹ - çœŸå®Tokenæ•°æ® (Original Tokens)\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"å›¾ç‰‡: {image_name}\n")
            f.write(f"æå–æ—¶é—´: {datetime.now()}\n")
            f.write(f"æ¨¡å‹: Infinity-8B (512x512)\n")
            f.write(f"VAEç±»å‹: {self.args.vae_type}\n")
            f.write(f"ç¼–ç æœ¬ç»´åº¦: {self.vae.codebook_dim}\n\n")
            
            for i, tokens in enumerate(gt_tokens):
                scale_info = self.vae_scale_schedule[i]
                token_shape = tokens.shape  # (B, T, H, W, D)
                token_count = token_shape[1] * token_shape[2] * token_shape[3]
                
                f.write("-" * 60 + "\n")
                f.write(f"Scale {i}: åˆ†è¾¨ç‡ {scale_info}\n")
                f.write("-" * 60 + "\n")
                f.write(f"Tokenå½¢çŠ¶: {token_shape}\n")
                f.write(f"Tokenæ•°é‡: {token_count}\n")
                f.write(f"æ¯ä¸ªtokençš„bitæ•°: {token_shape[-1]}\n")
                f.write(f"æ€»bitæ•°: {token_count * token_shape[-1]}\n\n")
                
                # å°†tokenæ•°æ®å±•å¹³å¹¶ä¿å­˜
                tokens_flat = tokens.squeeze(0).reshape(-1, token_shape[-1])  # (token_count, bit_dim)
                
                f.write("Tokenæ•°æ® (æ¯è¡Œä¸€ä¸ªtokenï¼Œæ¯ä¸ªæ•°å­—ä»£è¡¨ä¸€ä¸ªbit):\n")
                for token_idx, token in enumerate(tokens_flat):
                    bit_string = ''.join([str(int(bit.item())) for bit in token])
                    f.write(f"Token_{token_idx:04d}: {bit_string}\n")
                    
                    # ä¸ºäº†æ–‡ä»¶ä¸è¿‡å¤§ï¼Œæ¯ä¸ªå°ºåº¦æœ€å¤šä¿å­˜å‰100ä¸ªtokençš„è¯¦ç»†ä¿¡æ¯
                    if token_idx >= 99:
                        remaining = len(tokens_flat) - 100
                        if remaining > 0:
                            f.write(f"... (è¿˜æœ‰{remaining}ä¸ªtokenï¼Œæ ¼å¼ç›¸åŒ)\n")
                        break
                
                f.write("\n")
        
        # ä¿å­˜çº æ­£åtoken
        corrected_txt_path = os.path.join(output_dir, f"{image_name}_corrected_tokens.txt")
        with open(corrected_txt_path, 'w') as f:
            f.write("=" * 80 + "\n")
            f.write("Infinityæ¨¡å‹ - çº æ­£åTokenæ•°æ® (Self-Corrected Tokens)\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"å›¾ç‰‡: {image_name}\n")
            f.write(f"æå–æ—¶é—´: {datetime.now()}\n")
            f.write(f"æ¨¡å‹: Infinity-8B (512x512)\n")
            f.write(f"å™ªå£°åº”ç”¨å±‚æ•°: {self.noise_apply_layers}\n")
            f.write(f"å™ªå£°å¼ºåº¦: {self.noise_apply_strength}\n\n")
            
            for i, (gt_tokens_scale, corrected_tokens_scale) in enumerate(zip(gt_tokens, corrected_tokens)):
                scale_info = self.vae_scale_schedule[i]
                token_shape = corrected_tokens_scale.shape
                token_count = token_shape[1] * token_shape[2] * token_shape[3]
                
                f.write("-" * 60 + "\n")
                f.write(f"Scale {i}: åˆ†è¾¨ç‡ {scale_info}\n")
                f.write("-" * 60 + "\n")
                f.write(f"Tokenå½¢çŠ¶: {token_shape}\n")
                f.write(f"Tokenæ•°é‡: {token_count}\n")
                f.write(f"æ¯ä¸ªtokençš„bitæ•°: {token_shape[-1]}\n")
                
                # è®¡ç®—ä¸åŸå§‹tokençš„å·®å¼‚
                gt_flat = gt_tokens_scale.squeeze(0).reshape(-1, token_shape[-1])
                corrected_flat = corrected_tokens_scale.squeeze(0).reshape(-1, token_shape[-1])
                diff_mask = (gt_flat != corrected_flat)
                total_bits = gt_flat.numel()
                flipped_bits = diff_mask.sum().item()
                
                f.write(f"æ€»bitæ•°: {total_bits}\n")
                f.write(f"ç¿»è½¬çš„bitæ•°: {flipped_bits}\n")
                f.write(f"ç¿»è½¬æ¯”ä¾‹: {flipped_bits/total_bits*100:.2f}%\n\n")
                
                f.write("çº æ­£åTokenæ•°æ® (æ¯è¡Œä¸€ä¸ªtokenï¼Œ*æ ‡è®°è¡¨ç¤ºä¸åŸå§‹tokenä¸åŒçš„bit):\n")
                for token_idx, (gt_token, corrected_token) in enumerate(zip(gt_flat, corrected_flat)):
                    # åˆ›å»ºbitå­—ç¬¦ä¸²ï¼Œæ ‡è®°å·®å¼‚
                    bit_string = ""
                    for bit_idx, (gt_bit, corr_bit) in enumerate(zip(gt_token, corrected_token)):
                        if gt_bit != corr_bit:
                            bit_string += f"{int(corr_bit.item())}*"  # æ ‡è®°ç¿»è½¬çš„bit
                        else:
                            bit_string += str(int(corr_bit.item()))
                    
                    f.write(f"Token_{token_idx:04d}: {bit_string}\n")
                    
                    # é™åˆ¶è¾“å‡ºæ•°é‡
                    if token_idx >= 99:
                        remaining = len(corrected_flat) - 100
                        if remaining > 0:
                            f.write(f"... (è¿˜æœ‰{remaining}ä¸ªtokenï¼Œæ ¼å¼ç›¸åŒ)\n")
                        break
                
                f.write("\n")
        
        print(f"çœŸå®tokenæ•°æ®å·²ä¿å­˜åˆ°: {gt_txt_path}")
        print(f"çº æ­£åtokenæ•°æ®å·²ä¿å­˜åˆ°: {corrected_txt_path}")
        
        # åˆ›å»ºæ±‡æ€»ç»Ÿè®¡æ–‡ä»¶
        summary_path = os.path.join(output_dir, f"{image_name}_token_summary.txt")
        with open(summary_path, 'w') as f:
            f.write("Tokenæ•°é‡æ±‡æ€» - Multi-scale Token Summary\n")
            f.write("=" * 50 + "\n\n")
            
            total_tokens = 0
            total_bits = 0
            
            for i, tokens in enumerate(gt_tokens):
                scale_info = self.vae_scale_schedule[i]
                token_shape = tokens.shape
                token_count = token_shape[1] * token_shape[2] * token_shape[3]
                bit_count = token_count * token_shape[-1]
                
                total_tokens += token_count
                total_bits += bit_count
                
                f.write(f"Scale {i}: {scale_info}\n")
                f.write(f"  Tokenæ•°é‡: {token_count:,}\n")
                f.write(f"  æ¯ä¸ªtoken bitæ•°: {token_shape[-1]}\n")
                f.write(f"  è¯¥å°ºåº¦æ€»bitæ•°: {bit_count:,}\n\n")
            
            f.write("-" * 30 + "\n")
            f.write(f"æ€»è®¡:\n")
            f.write(f"  æ‰€æœ‰å°ºåº¦tokenæ€»æ•°: {total_tokens:,}\n")
            f.write(f"  æ‰€æœ‰å°ºåº¦bitæ€»æ•°: {total_bits:,}\n")
            f.write(f"  å¹³å‡æ¯ä¸ªtoken bitæ•°: {total_bits/total_tokens:.1f}\n")
        
        print(f"Tokenæ±‡æ€»å·²ä¿å­˜åˆ°: {summary_path}")
        
    def extract_from_image(self, image_path):
        """
        ä»å›¾ç‰‡æå–å¤šå°ºåº¦tokençš„å®Œæ•´æµç¨‹
        
        è¿™æ˜¯æ•´ä¸ªç±»çš„ä¸»è¦æ¥å£ï¼Œå°è£…äº†ä»å›¾ç‰‡åŠ è½½åˆ°ç»“æœä¿å­˜çš„å®Œæ•´æµç¨‹ã€‚
        """
        # è·å–å›¾ç‰‡åç§°ï¼ˆç”¨äºæ–‡ä»¶å‘½åï¼‰
        image_name = os.path.splitext(os.path.basename(image_path))[0]
        output_dir = os.path.join(OUTPUT_DIR, image_name)
        
        print(f"å¼€å§‹å¤„ç†å›¾ç‰‡: {image_path}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        
        # 1. é¢„å¤„ç†å›¾ç‰‡
        inp_B3HW, original_image = self.preprocess_image(image_path)
        
        # 2. æå–åŸå§‹ç‰¹å¾
        raw_features = self.extract_raw_features(inp_B3HW)
        
        # 3. æå–å¤šå°ºåº¦token
        gt_tokens, corrected_tokens = self.extract_multiscale_tokens(raw_features)
        
        # 4. é‡æ„å›¾ç‰‡ç”¨äºå¯è§†åŒ–
        gt_reconstructed = self.reconstruct_images(gt_tokens, "çœŸå®token")
        corrected_reconstructed = self.reconstruct_images(corrected_tokens, "çº æ­£åtoken")
        
        # 5. ä¿å­˜ç»“æœ
        self.save_tokens(gt_tokens, corrected_tokens, output_dir, image_name)
        self.save_tokens_as_txt(gt_tokens, corrected_tokens, output_dir, image_name)
        self.save_visualizations(
            gt_reconstructed, corrected_reconstructed, 
            original_image, output_dir, image_name, gt_tokens, corrected_tokens
        )
        
        print(f"\nâœ… å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        return gt_tokens, corrected_tokens

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Infinityå¤šå°ºåº¦è§†è§‰è¡¨å¾æå–å™¨")
    print("=" * 60)
    
    # æ£€æŸ¥å›¾ç‰‡è·¯å¾„
    if not os.path.exists(IMAGE_PATH):
        print(f"âŒ é”™è¯¯ï¼šå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {IMAGE_PATH}")
        print("è¯·ä¿®æ”¹è„šæœ¬å¼€å¤´çš„IMAGE_PATHå˜é‡ä¸ºæ­£ç¡®çš„å›¾ç‰‡è·¯å¾„")
        return
    
    # åˆ›å»ºæå–å™¨å¹¶åŠ è½½æ¨¡å‹
    extractor = MultiscaleTokenExtractor(args)
    extractor.load_model()
    
    # æå–token
    try:
        gt_tokens, corrected_tokens = extractor.extract_from_image(IMAGE_PATH)
        
        print("\n" + "=" * 60)
        print("æå–æ‘˜è¦:")
        print("=" * 60)
        print(f"âœ… æˆåŠŸæå–äº† {len(gt_tokens)} ä¸ªå°ºåº¦çš„è§†è§‰è¡¨å¾")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {OUTPUT_DIR}")
        print(f"ğŸ–¼ï¸ å¯è§†åŒ–å›¾ç‰‡å¯ç”¨äºåˆ†æä¸åŒå°ºåº¦æ•è·çš„è§†è§‰ä¿¡æ¯")
        print(f"ğŸ’¾ Tokenæ•°æ®å·²ä¿å­˜ï¼Œå¯ç”¨äºåç»­åˆ†æ")
        
    except Exception as e:
        print(f"âŒ æå–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
