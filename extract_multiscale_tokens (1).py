"""
Multi-scale Visual Token Extractor for Infinity Model

è¿™ä¸ªè„šæœ¬çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯ä»è¾“å…¥å›¾ç‰‡ä¸­æå–å‰4ä¸ªscaleçš„ä¸¤ç§è§†è§‰è¡¨å¾ï¼š
1. åŸå§‹tokenï¼ˆgt_tokensï¼‰ï¼šæœªç»æ‰°åŠ¨çš„çœŸå®è§†è§‰è¡¨å¾
2. çº æ­£åtokenï¼ˆcorrected_tokensï¼‰ï¼šç»è¿‡bitwise self-correctionå¤„ç†çš„è¡¨å¾

ä½¿ç”¨æ–¹æ³•ï¼š
1. ä¿®æ”¹IMAGE_PATHå˜é‡ä¸ºæ‚¨è¦åˆ†æçš„å›¾ç‰‡è·¯å¾„
2. è¿è¡Œ: python extract_multiscale_tokens.py
3. æŸ¥çœ‹è¾“å‡ºç›®å½•ä¸­ä¿å­˜çš„tokenæ–‡ä»¶å’Œå¯è§†åŒ–ç»“æœ
"""

import os
import random
import torch
torch.cuda.set_device(0)
import cv2
import numpy as np
from tools.run_infinity import *
from PIL import Image
import torch.nn.functional as F
from datetime import datetime

# ===================== é…ç½®éƒ¨åˆ† =====================
# åªéœ€è¦ä¿®æ”¹è¿™ä¸ªè·¯å¾„ï¼
IMAGE_PATH = "path/to/your/image.jpg"  # ä¿®æ”¹ä¸ºæ‚¨çš„å›¾ç‰‡è·¯å¾„

# æ¨¡å‹é…ç½®ï¼ˆä¸inf.pyä¿æŒä¸€è‡´ï¼‰
model_path = 'weights/infinity_8b_512x512_weights'
vae_path = 'weights/infinity_vae_d56_f8_14_patchify.pth'
text_encoder_ckpt = 'weights/flan-t5-xl-official'

# è¾“å‡ºç›®å½•
OUTPUT_DIR = "extracted_tokens"

# ===================== æ¨¡å‹é…ç½® =====================
args = argparse.Namespace(
    pn='0.25M',
    model_path=model_path,
    cfg_insertion_layer=0,
    vae_type=14,
    vae_path=vae_path,
    add_lvl_embeding_only_first_block=1,
    use_bit_label=1,
    model_type='infinity_8b',
    rope2d_each_sa_layer=1,
    rope2d_normalized_by_hw=2,
    use_scale_schedule_embedding=0,
    sampling_per_bits=1,
    text_encoder_ckpt=text_encoder_ckpt,
    text_channels=2048,
    apply_spatial_patchify=1,
    h_div_w_template=1.000,
    use_flex_attn=0,
    cache_dir='/dev/shm',
    checkpoint_type='torch_shard',
    seed=0,
    bf16=1,
)

class MultiscaleTokenExtractor:
    """
    å¤šå°ºåº¦tokenæå–å™¨
    
    è¿™ä¸ªç±»å°è£…äº†ä»å›¾ç‰‡åˆ°å¤šå°ºåº¦è§†è§‰è¡¨å¾çš„å®Œæ•´æµç¨‹ï¼Œ
    åŒ…æ‹¬é¢„å¤„ç†ã€VAEç¼–ç ã€Bitwise Self-Correctionç­‰æ­¥éª¤ã€‚
    """
    
    def __init__(self, args):
        self.args = args
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.vae = None
        self.scale_schedule = None
        self.vae_scale_schedule = None
        
        # BSCç›¸å…³å‚æ•°
        self.noise_apply_layers = 4  # å‰4å±‚éƒ½å¯èƒ½æ·»åŠ å™ªå£°
        self.noise_apply_strength = 0.15  # å™ªå£°å¼ºåº¦
        
    def load_model(self):
        """åŠ è½½VAEæ¨¡å‹"""
        print("æ­£åœ¨åŠ è½½VAEæ¨¡å‹...")
        self.vae = load_visual_tokenizer(self.args)
        print(f"VAEåŠ è½½å®Œæˆã€‚Codebookç»´åº¦: {self.vae.codebook_dim}")
        
        # è·å–scale_schedule
        h_div_w_template = self.args.h_div_w_template
        self.scale_schedule = dynamic_resolution_h_w[h_div_w_template][self.args.pn]['scales']
        self.scale_schedule = [(1, h, w) for (_, h, w) in self.scale_schedule]
        
        # å¦‚æœä½¿ç”¨spatial_patchifyï¼Œè½¬æ¢ä¸ºvae_scale_schedule
        if self.args.apply_spatial_patchify:
            self.vae_scale_schedule = [(pt, 2*ph, 2*pw) for pt, ph, pw in self.scale_schedule]
        else:
            self.vae_scale_schedule = self.scale_schedule
            
        print(f"Scale schedule: {self.scale_schedule[:6]}")
        print(f"VAE scale schedule: {self.vae_scale_schedule[:6]}")
        
    def preprocess_image(self, image_path):
        """
        å›¾ç‰‡é¢„å¤„ç†ï¼šå°†ä»»æ„å°ºå¯¸çš„å›¾ç‰‡è½¬æ¢ä¸º512x512
        
        å¤„ç†æµç¨‹ï¼š
        1. åŠ è½½å›¾ç‰‡
        2. æ™ºèƒ½resizeï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
        3. Center cropåˆ°512x512
        4. å½’ä¸€åŒ–åˆ°[-1, 1]èŒƒå›´
        """
        print(f"æ­£åœ¨é¢„å¤„ç†å›¾ç‰‡: {image_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        
        # åŠ è½½å›¾ç‰‡
        pil_image = Image.open(image_path).convert('RGB')
        original_size = pil_image.size
        print(f"åŸå§‹å›¾ç‰‡å°ºå¯¸: {original_size[0]}x{original_size[1]}")
        
        # ä½¿ç”¨transformå‡½æ•°è¿›è¡Œé¢„å¤„ç†
        tgt_h, tgt_w = 512, 512
        transformed = transform(pil_image, tgt_h, tgt_w)
        
        # æ·»åŠ batchç»´åº¦å¹¶ç§»åˆ°GPU
        inp_B3HW = transformed.unsqueeze(0).to(self.device)
        print(f"é¢„å¤„ç†åå½¢çŠ¶: {inp_B3HW.shape}")
        print(f"æ•°å€¼èŒƒå›´: [{inp_B3HW.min():.3f}, {inp_B3HW.max():.3f}]")
        
        return inp_B3HW, pil_image
        
    def extract_raw_features(self, inp_B3HW):
        """
        ä½¿ç”¨VAEæå–åŸå§‹ç‰¹å¾
        
        è¿™ä¸€æ­¥å°†å›¾ç‰‡ç¼–ç ä¸ºè¿ç»­çš„ç‰¹å¾è¡¨ç¤ºï¼Œ
        ä½œä¸ºåç»­å¤šå°ºåº¦é‡åŒ–çš„è¾“å…¥ã€‚
        """
        print("\næ­£åœ¨æå–VAEåŸå§‹ç‰¹å¾...")
        
        with torch.no_grad():
            raw_features, _, _ = self.vae.encode_for_raw_features(
                inp_B3HW, scale_schedule=self.vae_scale_schedule
            )
        
        print(f"Raw featureså½¢çŠ¶: {raw_features.shape}")
        print(f"Raw featuresæ•°å€¼èŒƒå›´: [{raw_features.min():.3f}, {raw_features.max():.3f}]")
        
        return raw_features
        
    def extract_multiscale_tokens(self, raw_features):
        """
        æå–å¤šå°ºåº¦tokenè¡¨å¾
        
        è¿™æ˜¯æ•´ä¸ªæµç¨‹çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œå®ç°äº†Bitwise Self-Correctionæœºåˆ¶ï¼š
        1. é€å°ºåº¦å¤„ç†residualç‰¹å¾
        2. å¯¹æ¯ä¸ªå°ºåº¦è¿›è¡ŒBSQé‡åŒ–
        3. åœ¨å‰å‡ ä¸ªå°ºåº¦æ·»åŠ å™ªå£°æ¨¡æ‹Ÿæ¨ç†é”™è¯¯
        4. ç´¯ç§¯å„å°ºåº¦çš„è´¡çŒ®
        
        è¿”å›ä¸¤ç§tokenï¼š
        - gt_tokens: çœŸå®çš„ã€æœªæ‰°åŠ¨çš„token
        - corrected_tokens: ç»è¿‡self-correctionçš„token
        """
        print("\næ­£åœ¨æå–å¤šå°ºåº¦token...")
        
        B = raw_features.shape[0]
        
        # å¤„ç†ç»´åº¦ï¼šç¡®ä¿æ˜¯5D tensor (B, C, T, H, W)
        if raw_features.dim() == 4:
            codes_out = raw_features.unsqueeze(2)  # æ·»åŠ æ—¶é—´ç»´åº¦
        else:
            codes_out = raw_features
            
        print(f"åˆå§‹codes_outå½¢çŠ¶: {codes_out.shape}")
        
        # åˆå§‹åŒ–ç´¯ç§¯å˜é‡å’Œç»“æœåˆ—è¡¨
        cum_var_input = 0
        gt_tokens = []  # çœŸå®token
        corrected_tokens = []  # çº æ­£åtoken
        
        with torch.no_grad():
            # é€å°ºåº¦å¤„ç†ï¼ˆåªå¤„ç†å‰4ä¸ªå°ºåº¦ï¼‰
            for si, (pt, ph, pw) in enumerate(self.vae_scale_schedule[:4]):
                print(f"\n--- å¤„ç†Scale {si}: ({pt}, {ph}, {pw}) ---")
                
                # è®¡ç®—å½“å‰å°ºåº¦çš„residual
                residual = codes_out - cum_var_input
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªå°ºåº¦ï¼Œéœ€è¦æ’å€¼åˆ°å½“å‰å°ºåº¦çš„åˆ†è¾¨ç‡
                if si < len(self.vae_scale_schedule) - 1:
                    residual = F.interpolate(
                        residual, 
                        size=(pt, ph, pw), 
                        mode=self.vae.quantizer.z_interplote_down
                    ).contiguous()
                
                print(f"Residualå½¢çŠ¶: {residual.shape}")
                
                # BSQé‡åŒ–å¾—åˆ°çœŸå®token
                quantized, _, bit_indices, _ = self.vae.quantizer.lfq(residual)
                gt_tokens.append(bit_indices.clone())
                
                print(f"Scale {si} tokenå½¢çŠ¶: {bit_indices.shape}")
                print(f"Tokenæ•°é‡: {bit_indices.numel() // bit_indices.shape[-1]} tokensï¼Œæ¯ä¸ªtoken {bit_indices.shape[-1]} bits")
                
                # ç”Ÿæˆçº æ­£åçš„tokenï¼ˆæ¨¡æ‹Ÿbitwise self-correctionï¼‰
                corrected_bit_indices = bit_indices.clone()
                
                # åœ¨å‰å‡ ä¸ªå°ºåº¦æ·»åŠ å™ªå£°
                if si < self.noise_apply_layers:
                    # éšæœºé€‰æ‹©è¦ç¿»è½¬çš„bits
                    noise_strength = self.noise_apply_strength * (1.0 - si * 0.05)  # å°ºåº¦è¶Šé«˜å™ªå£°è¶Šå°‘
                    mask = torch.rand_like(bit_indices, dtype=torch.float) < noise_strength
                    corrected_bit_indices[mask] = 1 - corrected_bit_indices[mask]
                    
                    flipped_bits = mask.sum().item()
                    total_bits = bit_indices.numel()
                    print(f"æ·»åŠ å™ªå£°ï¼šç¿»è½¬äº† {flipped_bits}/{total_bits} bits ({flipped_bits/total_bits*100:.2f}%)")
                else:
                    print("æœªæ·»åŠ å™ªå£°ï¼ˆå°ºåº¦è¿‡é«˜ï¼‰")
                
                corrected_tokens.append(corrected_bit_indices)
                
                # ç´¯ç§¯å½“å‰å°ºåº¦çš„è´¡çŒ®
                cum_var_input = cum_var_input + F.interpolate(
                    quantized, 
                    size=self.vae_scale_schedule[-1][::-1],  # (W, H, T) -> (T, H, W)
                    mode=self.vae.quantizer.z_interplote_up
                ).contiguous()
        
        print(f"\næå–å®Œæˆï¼å…±æå–äº† {len(gt_tokens)} ä¸ªå°ºåº¦çš„token")
        return gt_tokens, corrected_tokens
    
    def reconstruct_images(self, tokens_list, token_type=""):
        """
        ä»tokené‡æ„å›¾ç‰‡
        
        ä½¿ç”¨VAEçš„decoderå°†æ¯ä¸ªå°ºåº¦çš„tokené‡æ„ä¸ºå›¾ç‰‡ï¼Œ
        è¿™æœ‰åŠ©äºå¯è§†åŒ–ä¸åŒå°ºåº¦æ•è·çš„è§†è§‰ä¿¡æ¯ã€‚
        """
        print(f"\næ­£åœ¨é‡æ„{token_type}å›¾ç‰‡...")
        
        reconstructed_images = []
        
        with torch.no_grad():
            for si, tokens in enumerate(tokens_list):
                try:
                    # å°†bit indicesè½¬æ¢ä¸ºcodes
                    codes = self.vae.quantizer.lfq.indices_to_codes(
                        tokens, label_type='bit_label'
                    )
                    
                    # æ’å€¼åˆ°æœ€ç»ˆå°ºå¯¸å¹¶è§£ç 
                    final_size = self.vae_scale_schedule[-1]
                    codes_upsampled = F.interpolate(
                        codes, 
                        size=final_size, 
                        mode=self.vae.quantizer.z_interplote_up
                    )
                    
                    # VAEè§£ç 
                    if codes_upsampled.dim() == 5:
                        codes_upsampled = codes_upsampled.squeeze(2)  # ç§»é™¤æ—¶é—´ç»´åº¦
                    
                    reconstructed = self.vae.decode(codes_upsampled)
                    
                    # è½¬æ¢ä¸ºå¯æ˜¾ç¤ºçš„å›¾ç‰‡æ ¼å¼
                    img = (reconstructed + 1) / 2  # [-1,1] -> [0,1]
                    img = img.clamp(0, 1)
                    img = img.squeeze(0).permute(1, 2, 0)  # CHW -> HWC
                    img = (img * 255).cpu().numpy().astype(np.uint8)
                    
                    reconstructed_images.append(img)
                    print(f"Scale {si} é‡æ„å›¾ç‰‡å½¢çŠ¶: {img.shape}")
                    
                except Exception as e:
                    print(f"Scale {si} é‡æ„å¤±è´¥: {e}")
                    # åˆ›å»ºç©ºç™½å›¾ç‰‡ä½œä¸ºå ä½ç¬¦
                    reconstructed_images.append(np.zeros((512, 512, 3), dtype=np.uint8))
        
        return reconstructed_images
    
    def save_tokens(self, gt_tokens, corrected_tokens, output_dir, image_name):
        """ä¿å­˜æå–çš„tokenåˆ°æ–‡ä»¶"""
        print(f"\næ­£åœ¨ä¿å­˜tokenåˆ° {output_dir}")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜tokenæ•°æ®
        token_data = {
            'gt_tokens': gt_tokens,
            'corrected_tokens': corrected_tokens,
            'scale_schedule': self.scale_schedule[:4],
            'vae_scale_schedule': self.vae_scale_schedule[:4],
            'image_name': image_name,
            'extraction_time': datetime.now().isoformat(),
            'model_config': {
                'vae_type': self.args.vae_type,
                'apply_spatial_patchify': self.args.apply_spatial_patchify,
                'codebook_dim': self.vae.codebook_dim,
            }
        }
        
        token_file = os.path.join(output_dir, f"{image_name}_tokens.pt")
        torch.save(token_data, token_file)
        print(f"Tokenæ•°æ®å·²ä¿å­˜åˆ°: {token_file}")
        
        # ä¿å­˜tokenç»Ÿè®¡ä¿¡æ¯
        stats_file = os.path.join(output_dir, f"{image_name}_stats.txt")
        with open(stats_file, 'w') as f:
            f.write(f"Multi-scale Token Extraction Statistics\n")
            f.write(f"========================================\n\n")
            f.write(f"Image: {image_name}\n")
            f.write(f"Extraction Time: {datetime.now()}\n")
            f.write(f"Model: Infinity-8B (512x512)\n")
            f.write(f"VAE Type: {self.args.vae_type}\n")
            f.write(f"Codebook Dimension: {self.vae.codebook_dim}\n")
            f.write(f"Spatial Patchify: {self.args.apply_spatial_patchify}\n\n")
            
            f.write("Scale Information:\n")
            for i, (gt_token, corrected_token) in enumerate(zip(gt_tokens, corrected_tokens)):
                scale_info = self.vae_scale_schedule[i]
                token_count = gt_token.shape[1] * gt_token.shape[2] * gt_token.shape[3]
                bit_count = token_count * gt_token.shape[-1]
                
                f.write(f"Scale {i}: {scale_info}\n")
                f.write(f"  Tokenå½¢çŠ¶: {gt_token.shape}\n")
                f.write(f"  Tokenæ•°é‡: {token_count}\n")
                f.write(f"  æ€»bitæ•°: {bit_count}\n")
                f.write(f"  æ¯token bitæ•°: {gt_token.shape[-1]}\n\n")
        
        print(f"ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_file}")
        
    def save_visualizations(self, gt_reconstructed, corrected_reconstructed, 
                          original_image, output_dir, image_name):
        """ä¿å­˜å¯è§†åŒ–ç»“æœ"""
        print(f"\næ­£åœ¨ä¿å­˜å¯è§†åŒ–ç»“æœ...")
        
        # ä¿å­˜åŸå§‹å›¾ç‰‡
        original_path = os.path.join(output_dir, f"{image_name}_original.jpg")
        original_image.save(original_path)
        
        # ä¿å­˜å„ä¸ªå°ºåº¦çš„é‡æ„å›¾ç‰‡
        for i, (gt_img, corrected_img) in enumerate(zip(gt_reconstructed, corrected_reconstructed)):
            # çœŸå®tokené‡æ„çš„å›¾ç‰‡
            gt_path = os.path.join(output_dir, f"{image_name}_scale{i}_gt_reconstructed.jpg")
            cv2.imwrite(gt_path, gt_img[:, :, ::-1])  # RGB -> BGR
            
            # çº æ­£åtokené‡æ„çš„å›¾ç‰‡
            corrected_path = os.path.join(output_dir, f"{image_name}_scale{i}_corrected_reconstructed.jpg")
            cv2.imwrite(corrected_path, corrected_img[:, :, ::-1])  # RGB -> BGR
            
            print(f"Scale {i} å¯è§†åŒ–å·²ä¿å­˜")
        
        # åˆ›å»ºå¯¹æ¯”å›¾
        self.create_comparison_visualization(
            gt_reconstructed, corrected_reconstructed, 
            output_dir, image_name
        )
    
    def create_comparison_visualization(self, gt_reconstructed, corrected_reconstructed, 
                                     output_dir, image_name):
        """åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–å›¾"""
        print("æ­£åœ¨åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–...")
        
        # åˆ›å»º2x4çš„å¯¹æ¯”å›¾ (2è¡Œï¼Œ4åˆ—)
        fig_height = 512 * 2
        fig_width = 512 * 4
        comparison = np.zeros((fig_height, fig_width, 3), dtype=np.uint8)
        
        for i in range(4):
            # ç¬¬ä¸€è¡Œï¼šçœŸå®tokené‡æ„
            y1, y2 = 0, 512
            x1, x2 = i * 512, (i + 1) * 512
            comparison[y1:y2, x1:x2] = gt_reconstructed[i]
            
            # ç¬¬äºŒè¡Œï¼šçº æ­£åtokené‡æ„
            y1, y2 = 512, 1024
            comparison[y1:y2, x1:x2] = corrected_reconstructed[i]
        
        # æ·»åŠ æ ‡ç­¾ï¼ˆç®€å•çš„æ–¹å¼ï¼‰
        comparison_path = os.path.join(output_dir, f"{image_name}_comparison.jpg")
        cv2.imwrite(comparison_path, comparison[:, :, ::-1])  # RGB -> BGR
        print(f"å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {comparison_path}")
        
    def extract_from_image(self, image_path):
        """
        ä»å›¾ç‰‡æå–å¤šå°ºåº¦tokençš„å®Œæ•´æµç¨‹
        
        è¿™æ˜¯æ•´ä¸ªç±»çš„ä¸»è¦æ¥å£ï¼Œå°è£…äº†ä»å›¾ç‰‡åŠ è½½åˆ°ç»“æœä¿å­˜çš„å®Œæ•´æµç¨‹ã€‚
        """
        # è·å–å›¾ç‰‡åç§°ï¼ˆç”¨äºæ–‡ä»¶å‘½åï¼‰
        image_name = os.path.splitext(os.path.basename(image_path))[0]
        output_dir = os.path.join(OUTPUT_DIR, image_name)
        
        print(f"å¼€å§‹å¤„ç†å›¾ç‰‡: {image_path}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        
        # 1. é¢„å¤„ç†å›¾ç‰‡
        inp_B3HW, original_image = self.preprocess_image(image_path)
        
        # 2. æå–åŸå§‹ç‰¹å¾
        raw_features = self.extract_raw_features(inp_B3HW)
        
        # 3. æå–å¤šå°ºåº¦token
        gt_tokens, corrected_tokens = self.extract_multiscale_tokens(raw_features)
        
        # 4. é‡æ„å›¾ç‰‡ç”¨äºå¯è§†åŒ–
        gt_reconstructed = self.reconstruct_images(gt_tokens, "çœŸå®token")
        corrected_reconstructed = self.reconstruct_images(corrected_tokens, "çº æ­£åtoken")
        
        # 5. ä¿å­˜ç»“æœ
        self.save_tokens(gt_tokens, corrected_tokens, output_dir, image_name)
        self.save_visualizations(
            gt_reconstructed, corrected_reconstructed, 
            original_image, output_dir, image_name
        )
        
        print(f"\nâœ… å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        return gt_tokens, corrected_tokens

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Infinityå¤šå°ºåº¦è§†è§‰è¡¨å¾æå–å™¨")
    print("=" * 60)
    
    # æ£€æŸ¥å›¾ç‰‡è·¯å¾„
    if not os.path.exists(IMAGE_PATH):
        print(f"âŒ é”™è¯¯ï¼šå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {IMAGE_PATH}")
        print("è¯·ä¿®æ”¹è„šæœ¬å¼€å¤´çš„IMAGE_PATHå˜é‡ä¸ºæ­£ç¡®çš„å›¾ç‰‡è·¯å¾„")
        return
    
    # åˆ›å»ºæå–å™¨å¹¶åŠ è½½æ¨¡å‹
    extractor = MultiscaleTokenExtractor(args)
    extractor.load_model()
    
    # æå–token
    try:
        gt_tokens, corrected_tokens = extractor.extract_from_image(IMAGE_PATH)
        
        print("\n" + "=" * 60)
        print("æå–æ‘˜è¦:")
        print("=" * 60)
        print(f"âœ… æˆåŠŸæå–äº† {len(gt_tokens)} ä¸ªå°ºåº¦çš„è§†è§‰è¡¨å¾")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {OUTPUT_DIR}")
        print(f"ğŸ–¼ï¸ å¯è§†åŒ–å›¾ç‰‡å¯ç”¨äºåˆ†æä¸åŒå°ºåº¦æ•è·çš„è§†è§‰ä¿¡æ¯")
        print(f"ğŸ’¾ Tokenæ•°æ®å·²ä¿å­˜ï¼Œå¯ç”¨äºåç»­åˆ†æ")
        
    except Exception as e:
        print(f"âŒ æå–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
